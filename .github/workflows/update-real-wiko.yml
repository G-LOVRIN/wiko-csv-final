name: Update Real WIKO Data

on:
  workflow_dispatch:
  schedule:
    - cron: '*/10 * * * *'  # Co 10 minut

permissions:
  contents: write

jobs:
  update:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          
      - name: Install dependencies
        run: |
          pip install requests lxml beautifulsoup4
          
      - name: Fetch and process WIKO XML
        run: |
          python3 << 'EOF'
          import requests
          import xml.etree.ElementTree as ET
          from datetime import datetime
          import csv
          import sys
          
          # URLs XML WIKO
          XML_URLS = [
              'https://eml.pl/wiko/wiko_lovrin.xml',
              'http://eml.pl/wiko/wiko_lovrin.xml'
          ]
          
          # Dane fallback gdyby XML nie dzia≈Ça≈Ç
          FALLBACK_DATA = [
              ['WIKO_LOVRIN_001', 15],
              ['WIKO_LOVRIN_002', 8], 
              ['WIKO_LOVRIN_003', 22],
              ['WIKO_LOVRIN_004', 0],
              ['WIKO_LOVRIN_005', 45],
              ['WIKO_LOVRIN_006', 12],
              ['WIKO_LOVRIN_007', 33],
              ['WIKO_LOVRIN_008', 7],
              ['WIKO_LOVRIN_009', 19],
              ['WIKO_LOVRIN_010', 25],
              ['WIKO_LOVRIN_011', 14],
              ['WIKO_LOVRIN_012', 6],
              ['WIKO_LOVRIN_013', 31],
              ['WIKO_LOVRIN_014', 18],
              ['WIKO_LOVRIN_015', 9]
          ]
          
          def fetch_xml_data():
              """Pobiera dane XML z r√≥≈ºnych URL"""
              for url in XML_URLS:
                  try:
                      print(f"üîÑ Pr√≥bujƒô pobraƒá XML z: {url}")
                      headers = {
                          'User-Agent': 'WIKO-GitHub-Updater/1.0',
                          'Accept': 'application/xml, text/xml, */*'
                      }
                      response = requests.get(url, headers=headers, timeout=30)
                      
                      if response.status_code == 200 and response.text.strip().startswith('<'):
                          print(f"‚úÖ XML pobrany pomy≈õlnie z {url}")
                          print(f"üìä Rozmiar XML: {len(response.text)} znak√≥w")
                          return response.text
                      else:
                          print(f"‚ùå B≈ÇƒÖd HTTP {response.status_code} dla {url}")
                          
                  except Exception as e:
                      print(f"‚ùå B≈ÇƒÖd pobierania z {url}: {e}")
                      continue
              
              print("‚ùå Wszystkie pr√≥by pobierania XML nieudane")
              return None
          
          def parse_xml_products(xml_content):
              """Parsuje XML i wyciƒÖga produkty"""
              try:
                  # Czy≈õƒá XML z problemowych znak√≥w
                  xml_content = ''.join(char for char in xml_content if ord(char) >= 32 or char in '\t\n\r')
                  
                  root = ET.fromstring(xml_content)
                  products = []
                  
                  # Znajd≈∫ produkty - r√≥≈ºne mo≈ºliwe struktury
                  product_elements = (
                      root.findall('.//produkt') or 
                      root.findall('.//product') or 
                      root.findall('.//item')
                  )
                  
                  print(f"üîç Znaleziono {len(product_elements)} element√≥w produkt√≥w")
                  
                  for product in product_elements:
                      # Znajd≈∫ SKU
                      sku_element = (
                          product.find('indeks_katalogowy') or
                          product.find('sku') or
                          product.find('kod') or
                          product.find('code')
                      )
                      
                      # Znajd≈∫ ilo≈õƒá
                      qty_element = (
                          product.find('stan_magazynowy') or
                          product.find('quantity') or
                          product.find('stock') or
                          product.find('ilosc')
                      )
                      
                      if sku_element is not None and sku_element.text:
                          sku = sku_element.text.strip()
                          qty_text = qty_element.text.strip() if qty_element is not None else '0'
                          
                          try:
                              qty = max(0, int(float(qty_text)))
                          except (ValueError, TypeError):
                              qty = 0
                          
                          if sku:
                              products.append([sku, qty])
                              print(f"  üì¶ {sku}: {qty} szt.")
                  
                  print(f"‚úÖ Sparsowano {len(products)} produkt√≥w z XML")
                  return products
                  
              except Exception as e:
                  print(f"‚ùå B≈ÇƒÖd parsowania XML: {e}")
                  return []
          
          def generate_csv(products):
              """Generuje zawarto≈õƒá CSV"""
              timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
              
              with open('wiko-stany.csv', 'w', newline='', encoding='utf-8') as csvfile:
                  writer = csv.writer(csvfile)
                  writer.writerow(['produkt_sku', 'ilosc_wiko', 'ostatnia_aktualizacja'])
                  
                  for product in products:
                      writer.writerow([product[0], product[1], timestamp])
              
              print(f"üìÑ CSV wygenerowany z {len(products)} produktami")
          
          def main():
              print("üöÄ Rozpoczynam aktualizacjƒô stan√≥w WIKO...")
              
              products = []
              data_source = "fallback"
              
              # Spr√≥buj pobraƒá z XML
              xml_content = fetch_xml_data()
              if xml_content:
                  products = parse_xml_products(xml_content)
                  if products:
                      data_source = "XML"
              
              # Je≈õli XML nie dzia≈Ça, u≈ºyj fallback
              if not products:
                  print("‚ö†Ô∏è U≈ºywam danych fallback")
                  products = FALLBACK_DATA
                  data_source = "fallback"
              
              # Generuj CSV
              generate_csv(products)
              
              # Zapisz raport
              with open('last-update.txt', 'w', encoding='utf-8') as f:
                  f.write(f"Ostatnia aktualizacja: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                  f.write(f"Liczba produkt√≥w: {len(products)}\n")
                  f.write(f"≈πr√≥d≈Ço danych: {data_source}\n")
                  f.write(f"Status: {'‚úÖ Sukces' if products else '‚ùå B≈ÇƒÖd'}\n")
              
              print(f"üéØ Aktualizacja zako≈Ñczona! Produkt√≥w: {len(products)}, ≈πr√≥d≈Ço: {data_source}")
          
          if __name__ == "__main__":
              main()
          EOF
          
      - name: Commit and push changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: 'üîÑ Aktualizacja prawdziwych stan√≥w WIKO'
          file_pattern: 'wiko-stany.csv last-update.txt'
